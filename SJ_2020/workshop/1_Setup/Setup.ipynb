{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerated Machine Learning at Scale with NVIDIA RAPIDS on Microsoft Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom Drabas (Microsoft), Manuel Reyes-Gomez (NVIDIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore, Dataset, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from dask_cloudprovider import AzureMLCluster\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workspace\n",
    "\n",
    "Documentation: [Workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '6560575d-fa06-4e7d-95fb-f962e74efd7a'\n",
    "resource_group = 'azure-sandbox'\n",
    "workspace_name = 'todrabas_UK_STH'\n",
    "\n",
    "ws = Workspace(\n",
    "    workspace_name=workspace_name\n",
    "    , subscription_id=subscription_id\n",
    "    , resource_group=resource_group\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: gtc20-001\n",
      "\n",
      "vNET RG: azure-sandbox\n",
      "vNET name: todrabas_UK_STH_VN\n",
      "vNET subnet name: default\n",
      "\n",
      "Compute target: gtc20-001-ct\n",
      "Experiment name: gtc20-001-dask-demo\n",
      "\n",
      "Admin login name: gtc20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workshop_id = 1                      # REPLACE\n",
    "\n",
    "########################################################\n",
    "### DO NOT CHANGE ANYTHING BELOW\n",
    "########################################################\n",
    "\n",
    "name = f'GTC20-{workshop_id:03d}'.lower()\n",
    "\n",
    "### vnet settings\n",
    "vnet_rg = ws.resource_group\n",
    "vnet_name = 'todrabas_UK_STH_VN'\n",
    "subnet_name = 'default'\n",
    "\n",
    "### azure ml names\n",
    "ct_name  = f'{name}-ct'\n",
    "exp_name = f'{name}-dask-demo'\n",
    "\n",
    "### credentials\n",
    "admin_username = name.split('-')[0]\n",
    "admin_ssh_key_pub = '../../../ssh_key/gtc20_rsa.pub'\n",
    "admin_ssh_key_priv = '../../../ssh_key/gtc20_rsa'\n",
    "\n",
    "### trust but verify\n",
    "verify = f'''\n",
    "Name: {name}\n",
    "\n",
    "vNET RG: {vnet_rg}\n",
    "vNET name: {vnet_name}\n",
    "vNET subnet name: {subnet_name}\n",
    "\n",
    "Compute target: {ct_name}\n",
    "Experiment name: {exp_name}\n",
    "\n",
    "Admin login name: {admin_username}\n",
    "'''\n",
    "\n",
    "print(verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute target\n",
    "Documentation: [Compute target](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.amlcompute(class)?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_name = 'STANDARD_NC6S_V3'\n",
    "gpus_per_node = 1\n",
    "\n",
    "with open(admin_ssh_key_pub, 'r') as f:\n",
    "    ssh_key_pub = f.read().strip()\n",
    "    \n",
    "if ct_name not in ws.compute_targets:\n",
    "    # create config for Azure ML cluster\n",
    "    # change properties as needed\n",
    "    config = AmlCompute.provisioning_configuration(\n",
    "          vm_size=vm_name\n",
    "        , min_nodes=0\n",
    "        , max_nodes=2\n",
    "        , vnet_resourcegroup_name=vnet_rg\n",
    "        , vnet_name=vnet_name\n",
    "        , subnet_name=subnet_name\n",
    "        , idle_seconds_before_scaledown=300\n",
    "        , admin_username=admin_username\n",
    "        , admin_user_ssh_key=ssh_key_pub\n",
    "        , remote_login_port_public_access='Enabled'   ### can switch to 'Disabled' if machine submitting this runs in the same VNET\n",
    "    )\n",
    "    ct = ComputeTarget.create(ws, ct_name, config)\n",
    "    ct.wait_for_completion(show_output=True)\n",
    "else:\n",
    "    ct = ws.compute_targets[ct_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment\n",
    "Documentation: [Environment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name='gtc20_GPU_ENV'\n",
    "docker_image='todrabas/aml_rapids:latest'\n",
    "python_interpreter = '/opt/conda/envs/rapids/bin/python'\n",
    "conda_packages = ['matplotlib']\n",
    "\n",
    "if environment_name not in ws.environments:\n",
    "    env = Environment(name=environment_name)\n",
    "    env.docker.enabled = True\n",
    "    env.docker.base_image = docker_image\n",
    "\n",
    "    env.python.interpreter_path = python_interpreter\n",
    "    env.python.user_managed_dependencies = True\n",
    " \n",
    "    conda_dep = CondaDependencies()\n",
    "\n",
    "    for conda_package in conda_packages:\n",
    "        conda_dep.add_conda_package(conda_package)\n",
    "\n",
    "    env.python.conda_dependencies = conda_dep\n",
    "    env.register(workspace=ws)\n",
    "    evn = env\n",
    "else:\n",
    "    env = ws.environments[environment_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYC Taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data = True\n",
    "years = ['2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################### Downloading data ###############################\n",
      "\n",
      "--> Downloading https://storage.googleapis.com/anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-01.csv <--\n",
      "#######-->> yellow_tripdata_2016-01.csv file already exists locally <<--########\n",
      "--> Downloading https://storage.googleapis.com/anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-02.csv <--\n",
      "#######-->> yellow_tripdata_2016-02.csv file already exists locally <<--########\n",
      "--> Downloading https://storage.googleapis.com/anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-03.csv <--\n",
      "#######-->> yellow_tripdata_2016-03.csv file already exists locally <<--########\n",
      "--> Downloading https://storage.googleapis.com/anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-04.csv <--\n",
      "#######-->> yellow_tripdata_2016-04.csv file already exists locally <<--########\n",
      "--> Downloading https://storage.googleapis.com/anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-05.csv <--\n",
      "#######-->> yellow_tripdata_2016-05.csv file already exists locally <<--########\n",
      "--> Downloading https://storage.googleapis.com/anaconda-public-data/nyc-taxi/csv/2016/yellow_tripdata_2016-06.csv <--\n",
      "#######-->> yellow_tripdata_2016-06.csv file already exists locally <<--########\n",
      "############################## Download complete ###############################\n",
      "################################ Uploading data ################################\n",
      "\n",
      "Uploading an estimated of 6 files\n",
      "Uploading /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-02.csv\n",
      "Uploading /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-03.csv\n",
      "Uploading /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-01.csv\n",
      "Uploading /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-04.csv\n",
      "Uploading /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-05.csv\n",
      "Uploading /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(32, 'EPIPE')\"))': /azureml-blobstore-9ec0472a-5bc1-4560-b17f-fdf630f9e35a/data/nyctaxi/2016/yellow_tripdata_2016-01.csv?comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQTNNemd4T1RjMU1EUSUzRA%3D%3D\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(32, 'EPIPE')\"))': /azureml-blobstore-9ec0472a-5bc1-4560-b17f-fdf630f9e35a/data/nyctaxi/2016/yellow_tripdata_2016-06.csv?comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQTNOekUzTlRFNU16WSUzRA%3D%3D\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(32, 'EPIPE')\"))': /azureml-blobstore-9ec0472a-5bc1-4560-b17f-fdf630f9e35a/data/nyctaxi/2016/yellow_tripdata_2016-06.csv?comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQTNOamMxTlRjMk16SSUzRA%3D%3D\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(60, 'ETIMEDOUT')\"))': /azureml-blobstore-9ec0472a-5bc1-4560-b17f-fdf630f9e35a/data/nyctaxi/2016/yellow_tripdata_2016-01.csv?comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQTNNelF3TURNeU1EQSUzRA%3D%3D\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(32, 'EPIPE')\"))': /azureml-blobstore-9ec0472a-5bc1-4560-b17f-fdf630f9e35a/data/nyctaxi/2016/yellow_tripdata_2016-05.csv?comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQTNNREEwTkRnM05qZyUzRA%3D%3D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-02.csv, 1 files out of an estimated total of 6\n",
      "Uploaded /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-01.csv, 2 files out of an estimated total of 6\n",
      "Uploaded /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-04.csv, 3 files out of an estimated total of 6\n",
      "Uploaded /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-03.csv, 4 files out of an estimated total of 6\n",
      "Uploaded /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-06.csv, 5 files out of an estimated total of 6\n",
      "Uploaded /Users/drabast/Documents/Programming/playground/python/GTC/SJ_2020/WORKSHOP/1_Setup/nyctaxi/2016/yellow_tripdata_2016-05.csv, 6 files out of an estimated total of 6\n",
      "Uploaded 6 files\n",
      "############################### Upload complete ################################\n"
     ]
    }
   ],
   "source": [
    "if get_data:\n",
    "    import nyc_data\n",
    "    \n",
    "    print(' Downloading data '.center(80, '#'))\n",
    "    print()\n",
    "    \n",
    "    nyc_data.download_nyctaxi_data(years, os.getcwd())\n",
    "    \n",
    "    print(' Uploading data '.center(80, '#'))\n",
    "    print()\n",
    "    nyc_data.upload_nyctaxi_data(\n",
    "        ws\n",
    "        , ws.get_default_datastore()\n",
    "        , os.path.join(os.getcwd(), 'nyctaxi')\n",
    "        , os.path.join('data', 'nyctaxi')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure ML Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## Setting up cluster ##############################\n",
      "########################## Submitting the experiment ###########################\n",
      "####################### Waiting for scheduler node's IP ########################\n",
      "........................................................................................\n",
      "\n",
      "\n",
      "########################### Scheduler: 10.7.0.5:8786 ###########################\n",
      "Checking connection...\n",
      "############################# Not on the same VNET #############################\n",
      "########################### Connections established ############################\n",
      "############################# Scaling to 1 workers #############################\n",
      "############################### Scaling is done ################################\n"
     ]
    }
   ],
   "source": [
    "amlcluster = AzureMLCluster(\n",
    "              workspace=ws\n",
    "            , compute_target=ct\n",
    "            , initial_node_count=1\n",
    "            , experiment_name=exp_name\n",
    "            , environment_definition=env\n",
    "            , use_gpu=True\n",
    "            , n_gpus_per_node=1\n",
    "            , admin_username=admin_username\n",
    "            , admin_ssh_key=admin_ssh_key_priv\n",
    "            , asynchronous=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7efb10089814539bf6416d075d3e2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>AzureMLCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amlcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Scheduler and workers are disconnected. ####################\n"
     ]
    }
   ],
   "source": [
    "amlcluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
